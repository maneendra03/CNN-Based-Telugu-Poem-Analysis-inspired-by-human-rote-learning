#!/usr/bin/env python
"""
‡∞µ‡∞ø‡∞∏‡±ç‡∞§‡±É‡∞§ ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞ï‡∞µ‡∞ø‡∞§‡∞æ ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç - Large Scale (520+ poems)
Comprehensive Telugu Poem Dataset Generator
"""

import json
import random
from pathlib import Path

# Import all dataset parts
from dataset_part1 import VEMANA_POEMS, SUMATI_SATAKAM
from dataset_part2 import ANNAMAYYA_KEERTANAS, FOLK_SONGS, POTHANA_BHAGAVATAM
from dataset_part3 import MODERN_POETRY, NEETI_POEMS
from dataset_part4 import SRINATHA_POEMS, TYAGARAJA_KEERTANAS, GURAJADA_POEMS
from dataset_part5 import TIKKANA_POEMS, RAMADASU_KEERTANAS, KRISHNASASTRI_POEMS, CHILAKAMARTHI_POEMS
from dataset_part6 import BHARTRUHARI_POEMS, NANNAYA_POEMS, SRISRI_POEMS


def create_large_telugu_dataset():
    """Create large-scale Telugu dataset with 520+ poems."""
    
    print("=" * 70)
    print("üì• ‡∞µ‡∞ø‡∞∏‡±ç‡∞§‡±É‡∞§ ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞ï‡∞µ‡∞ø‡∞§‡∞æ ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç (Large-Scale Telugu Dataset)")
    print("=" * 70)
    
    all_poems = []
    
    # Define categories with metadata
    categories = [
        (VEMANA_POEMS, '‡∞µ‡±á‡∞Æ‡∞® ‡∞™‡∞¶‡±ç‡∞Ø‡∞Ç', '‡∞µ‡±á‡∞Æ‡∞®', '‡∞Ü‡∞ü ‡∞µ‡±Ü‡∞≤‡∞¶‡∞ø', '18‡∞µ ‡∞∂‡∞§‡∞æ‡∞¨‡±ç‡∞¶‡∞Ç'),
        (SUMATI_SATAKAM, '‡∞∏‡±Å‡∞Æ‡∞§‡±Ä ‡∞∂‡∞§‡∞ï‡∞Ç', '‡∞¨‡∞¶‡±ç‡∞¶‡±Ü‡∞®', '‡∞ï‡∞Ç‡∞¶‡∞Ç', '14‡∞µ ‡∞∂‡∞§‡∞æ‡∞¨‡±ç‡∞¶‡∞Ç'),
        (ANNAMAYYA_KEERTANAS, '‡∞Ö‡∞®‡±ç‡∞®‡∞Æ‡∞Ø‡±ç‡∞Ø ‡∞ï‡±Ä‡∞∞‡±ç‡∞§‡∞®', '‡∞Ö‡∞®‡±ç‡∞®‡∞Æ‡∞Ø‡±ç‡∞Ø', '‡∞∏‡∞Ç‡∞ï‡±Ä‡∞∞‡±ç‡∞§‡∞®', '15‡∞µ ‡∞∂‡∞§‡∞æ‡∞¨‡±ç‡∞¶‡∞Ç'),
        (FOLK_SONGS, '‡∞ú‡∞æ‡∞®‡∞™‡∞¶ ‡∞ó‡±á‡∞Ø‡∞Ç', '‡∞ú‡∞æ‡∞®‡∞™‡∞¶', '‡∞ó‡±á‡∞Ø‡∞Ç', '‡∞∏‡∞Ç‡∞™‡±ç‡∞∞‡∞¶‡∞æ‡∞Ø'),
        (POTHANA_BHAGAVATAM, '‡∞≠‡∞æ‡∞ó‡∞µ‡∞§ ‡∞™‡∞¶‡±ç‡∞Ø‡∞Ç', '‡∞™‡±ã‡∞§‡∞®', '‡∞â‡∞§‡±ç‡∞™‡∞≤‡∞Æ‡∞æ‡∞≤', '15‡∞µ ‡∞∂‡∞§‡∞æ‡∞¨‡±ç‡∞¶‡∞Ç'),
        (MODERN_POETRY, '‡∞Ü‡∞ß‡±Å‡∞®‡∞ø‡∞ï ‡∞ï‡∞µ‡∞ø‡∞§', '‡∞Ü‡∞ß‡±Å‡∞®‡∞ø‡∞ï ‡∞ï‡∞µ‡∞ø', '‡∞µ‡∞ö‡∞® ‡∞ï‡∞µ‡∞ø‡∞§', '21‡∞µ ‡∞∂‡∞§‡∞æ‡∞¨‡±ç‡∞¶‡∞Ç'),
        (NEETI_POEMS, '‡∞®‡±Ä‡∞§‡∞ø ‡∞™‡∞¶‡±ç‡∞Ø‡∞Ç', '‡∞∏‡∞Ç‡∞™‡±ç‡∞∞‡∞¶‡∞æ‡∞Ø', '‡∞®‡±Ä‡∞§‡∞ø ‡∞∂‡∞§‡∞ï‡∞Ç', '‡∞∏‡∞Ç‡∞™‡±ç‡∞∞‡∞¶‡∞æ‡∞Ø'),
        (SRINATHA_POEMS, '‡∞∂‡±ç‡∞∞‡±Ä‡∞®‡∞æ‡∞• ‡∞™‡∞¶‡±ç‡∞Ø‡∞Ç', '‡∞∂‡±ç‡∞∞‡±Ä‡∞®‡∞æ‡∞•‡±Å‡∞°‡±Å', '‡∞™‡±ç‡∞∞‡∞¨‡∞Ç‡∞ß‡∞Ç', '15‡∞µ ‡∞∂‡∞§‡∞æ‡∞¨‡±ç‡∞¶‡∞Ç'),
        (TYAGARAJA_KEERTANAS, '‡∞§‡±ç‡∞Ø‡∞æ‡∞ó‡∞∞‡∞æ‡∞ú ‡∞ï‡±Ä‡∞∞‡±ç‡∞§‡∞®', '‡∞§‡±ç‡∞Ø‡∞æ‡∞ó‡∞∞‡∞æ‡∞ú‡±Å', '‡∞ï‡∞∞‡±ç‡∞£‡∞æ‡∞ü‡∞ï ‡∞∏‡∞Ç‡∞ó‡±Ä‡∞§‡∞Ç', '18‡∞µ ‡∞∂‡∞§‡∞æ‡∞¨‡±ç‡∞¶‡∞Ç'),
        (GURAJADA_POEMS, '‡∞ó‡±Å‡∞∞‡∞ú‡∞æ‡∞° ‡∞ï‡∞µ‡∞ø‡∞§', '‡∞ó‡±Å‡∞∞‡∞ú‡∞æ‡∞° ‡∞Ö‡∞™‡±ç‡∞™‡∞æ‡∞∞‡∞æ‡∞µ‡±Å', '‡∞∏‡∞æ‡∞Æ‡∞æ‡∞ú‡∞ø‡∞ï ‡∞ï‡∞µ‡∞ø‡∞§‡±ç‡∞µ‡∞Ç', '20‡∞µ ‡∞∂‡∞§‡∞æ‡∞¨‡±ç‡∞¶‡∞Ç'),
        (TIKKANA_POEMS, '‡∞§‡∞ø‡∞ï‡±ç‡∞ï‡∞® ‡∞™‡∞¶‡±ç‡∞Ø‡∞Ç', '‡∞§‡∞ø‡∞ï‡±ç‡∞ï‡∞®', '‡∞Æ‡∞π‡∞æ‡∞≠‡∞æ‡∞∞‡∞§‡∞Ç', '13‡∞µ ‡∞∂‡∞§‡∞æ‡∞¨‡±ç‡∞¶‡∞Ç'),
        (RAMADASU_KEERTANAS, '‡∞∞‡∞æ‡∞Æ‡∞¶‡∞æ‡∞∏‡±Å ‡∞ï‡±Ä‡∞∞‡±ç‡∞§‡∞®', '‡∞∞‡∞æ‡∞Æ‡∞¶‡∞æ‡∞∏‡±Å', '‡∞≠‡∞ï‡±ç‡∞§‡∞ø ‡∞ï‡±Ä‡∞∞‡±ç‡∞§‡∞®', '17‡∞µ ‡∞∂‡∞§‡∞æ‡∞¨‡±ç‡∞¶‡∞Ç'),
        (KRISHNASASTRI_POEMS, '‡∞ï‡±É‡∞∑‡±ç‡∞£‡∞∂‡∞æ‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞ø ‡∞ï‡∞µ‡∞ø‡∞§', '‡∞¶‡±á‡∞µ‡±Å‡∞≤‡∞™‡∞≤‡±ç‡∞≤‡∞ø ‡∞ï‡±É‡∞∑‡±ç‡∞£‡∞∂‡∞æ‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞ø', '‡∞≠‡∞æ‡∞µ ‡∞ï‡∞µ‡∞ø‡∞§‡±ç‡∞µ‡∞Ç', '20‡∞µ ‡∞∂‡∞§‡∞æ‡∞¨‡±ç‡∞¶‡∞Ç'),
        (CHILAKAMARTHI_POEMS, '‡∞ö‡∞ø‡∞≤‡∞ï‡∞Æ‡∞∞‡±ç‡∞§‡∞ø ‡∞∞‡∞ö‡∞®', '‡∞ö‡∞ø‡∞≤‡∞ï‡∞Æ‡∞∞‡±ç‡∞§‡∞ø', '‡∞π‡∞æ‡∞∏‡±ç‡∞Ø ‡∞ï‡∞µ‡∞ø‡∞§‡±ç‡∞µ‡∞Ç', '20‡∞µ ‡∞∂‡∞§‡∞æ‡∞¨‡±ç‡∞¶‡∞Ç'),
        (BHARTRUHARI_POEMS, '‡∞≠‡∞∞‡±ç‡∞§‡±É‡∞π‡∞∞‡∞ø ‡∞∏‡±Å‡∞≠‡∞æ‡∞∑‡∞ø‡∞§‡∞Ç', '‡∞≠‡∞∞‡±ç‡∞§‡±É‡∞π‡∞∞‡∞ø', '‡∞∏‡±Å‡∞≠‡∞æ‡∞∑‡∞ø‡∞§ ‡∞∂‡∞§‡∞ï‡∞Ç', '‡∞™‡±ç‡∞∞‡∞æ‡∞ö‡±Ä‡∞®'),
        (NANNAYA_POEMS, '‡∞®‡∞®‡±ç‡∞®‡∞Ø ‡∞™‡∞¶‡±ç‡∞Ø‡∞Ç', '‡∞®‡∞®‡±ç‡∞®‡∞Ø', '‡∞Æ‡∞π‡∞æ‡∞≠‡∞æ‡∞∞‡∞§‡∞Ç', '11‡∞µ ‡∞∂‡∞§‡∞æ‡∞¨‡±ç‡∞¶‡∞Ç'),
        (SRISRI_POEMS, '‡∞∂‡±ç‡∞∞‡±Ä‡∞∂‡±ç‡∞∞‡±Ä ‡∞ï‡∞µ‡∞ø‡∞§', '‡∞∂‡±ç‡∞∞‡±Ä‡∞∂‡±ç‡∞∞‡±Ä', '‡∞Ö‡∞≠‡±ç‡∞Ø‡±Å‡∞¶‡∞Ø ‡∞ï‡∞µ‡∞ø‡∞§‡±ç‡∞µ‡∞Ç', '20‡∞µ ‡∞∂‡∞§‡∞æ‡∞¨‡±ç‡∞¶‡∞Ç'),
    ]
    
    # Process each category
    for poems, title_prefix, author, style, era in categories:
        print(f"\nüìö {title_prefix}: {len(poems)} poems")
        for i, text in enumerate(poems):
            all_poems.append({
                'text': text.strip(),
                'title': f'{title_prefix} {i+1}',
                'author': author,
                'style': style,
                'era': era,
                'language': 'telugu'
            })
    
    # Save dataset
    output_dir = Path(__file__).parent.parent / "data" / "processed"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Shuffle and split (80/10/10)
    random.seed(42)
    random.shuffle(all_poems)
    
    n = len(all_poems)
    train_size = int(0.8 * n)
    val_size = int(0.1 * n)
    
    train_data = all_poems[:train_size]
    val_data = all_poems[train_size:train_size + val_size]
    test_data = all_poems[train_size + val_size:]
    
    # Save files
    with open(output_dir / 'telugu_train.json', 'w', encoding='utf-8') as f:
        json.dump(train_data, f, ensure_ascii=False, indent=2)
    
    with open(output_dir / 'telugu_val.json', 'w', encoding='utf-8') as f:
        json.dump(val_data, f, ensure_ascii=False, indent=2)
    
    with open(output_dir / 'telugu_test.json', 'w', encoding='utf-8') as f:
        json.dump(test_data, f, ensure_ascii=False, indent=2)
    
    with open(output_dir / 'telugu_poems.json', 'w', encoding='utf-8') as f:
        json.dump(all_poems, f, ensure_ascii=False, indent=2)
    
    # Collect stats
    styles = list(set(p['style'] for p in all_poems))
    authors = list(set(p['author'] for p in all_poems))
    eras = list(set(p['era'] for p in all_poems))
    
    stats = {
        'total_poems': len(all_poems),
        'train_poems': len(train_data),
        'val_poems': len(val_data),
        'test_poems': len(test_data),
        'styles': styles,
        'authors': authors,
        'eras': eras,
        'language': 'telugu'
    }
    
    with open(output_dir / 'telugu_stats.json', 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    # Print summary
    print("\n" + "=" * 70)
    print("‚úÖ ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø! (Telugu Dataset Created!)")
    print("=" * 70)
    print(f"\nüìä ‡∞Æ‡±ä‡∞§‡±ç‡∞§‡∞Ç ‡∞ï‡∞µ‡∞ø‡∞§‡∞≤‡±Å (Total Poems): {stats['total_poems']}")
    print(f"   ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ (Train): {stats['train_poems']}")
    print(f"   ‡∞ß‡±É‡∞µ‡±Ä‡∞ï‡∞∞‡∞£ (Validation): {stats['val_poems']}")
    print(f"   ‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑ (Test): {stats['test_poems']}")
    print(f"\nüìù ‡∞∂‡±à‡∞≤‡±Å‡∞≤‡±Å (Styles): {len(styles)}")
    for s in sorted(styles):
        print(f"   ‚Ä¢ {s}")
    print(f"\n‚úçÔ∏è ‡∞ï‡∞µ‡±Å‡∞≤‡±Å (Authors): {len(authors)}")
    for a in sorted(authors):
        print(f"   ‚Ä¢ {a}")
    print(f"\nüìÖ ‡∞Ø‡±Å‡∞ó‡∞æ‡∞≤‡±Å (Eras): {len(eras)}")
    for e in sorted(eras):
        print(f"   ‚Ä¢ {e}")
    
    print(f"\nüìÅ Output directory: {output_dir}")
    return all_poems


if __name__ == "__main__":
    create_large_telugu_dataset()
