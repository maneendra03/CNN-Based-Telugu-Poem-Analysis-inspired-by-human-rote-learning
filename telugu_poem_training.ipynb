{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéØ Telugu Poem Generator - Training Notebook\n",
                "\n",
                "**CNN-Based Telugu Poem Analysis Inspired by Human Rote Learning**\n",
                "\n",
                "This notebook trains the Telugu poem generation model using Google Colab's GPU."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Setup Environment\n",
                "\n",
                "First, mount Google Drive and install dependencies."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone or upload your project\n",
                "# Option 1: Clone from GitHub (if you have a repo)\n",
                "# !git clone https://github.com/your-username/telugu-poem-generator.git\n",
                "\n",
                "# Option 2: Upload project folder to Drive and copy\n",
                "!cp -r '/content/drive/MyDrive/majorproject - A' /content/project\n",
                "%cd /content/project"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install torch torchvision torchaudio\n",
                "!pip install transformers\n",
                "!pip install tqdm\n",
                "!pip install pyyaml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "import torch\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Load Dataset\n",
                "\n",
                "Load the Telugu poem dataset (470 poems)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "from pathlib import Path\n",
                "\n",
                "# Load Telugu poems\n",
                "data_path = Path('data/processed/telugu_poems.json')\n",
                "\n",
                "if not data_path.exists():\n",
                "    # Generate dataset if not exists\n",
                "    %cd scripts\n",
                "    !python create_large_dataset.py\n",
                "    %cd ..\n",
                "\n",
                "with open(data_path, 'r', encoding='utf-8') as f:\n",
                "    poems = json.load(f)\n",
                "\n",
                "print(f\"‚úÖ Loaded {len(poems)} Telugu poems\")\n",
                "print(f\"\\nüìù Sample poem:\")\n",
                "print(poems[0]['text'][:200])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Initialize Model\n",
                "\n",
                "Create the Telugu poem generator model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '/content/project')\n",
                "\n",
                "from src.models.telugu_backbone import create_telugu_generator\n",
                "\n",
                "# Create model\n",
                "# Options: 'distilmbert' (small), 'mbert' (medium), 'xlm-roberta' (large)\n",
                "model = create_telugu_generator('distilmbert', freeze_backbone=False)\n",
                "\n",
                "# Move to GPU\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "model = model.to(device)\n",
                "\n",
                "# Count parameters\n",
                "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "total = sum(p.numel() for p in model.parameters())\n",
                "print(f\"\\nüìä Model Statistics:\")\n",
                "print(f\"   Total parameters: {total:,}\")\n",
                "print(f\"   Trainable: {trainable:,} ({100*trainable/total:.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Prepare DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch.utils.data import Dataset, DataLoader\n",
                "from src.preprocessing.telugu_cleaner import TeluguTextCleaner\n",
                "\n",
                "class TeluguPoemDataset(Dataset):\n",
                "    def __init__(self, poems, tokenizer, max_length=128):\n",
                "        self.poems = poems\n",
                "        self.tokenizer = tokenizer\n",
                "        self.max_length = max_length\n",
                "        self.cleaner = TeluguTextCleaner()\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.poems)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        poem = self.poems[idx]\n",
                "        text = poem.get('text', '') if isinstance(poem, dict) else poem\n",
                "        text = self.cleaner.clean(text)\n",
                "        \n",
                "        encoding = self.tokenizer.encode_plus(\n",
                "            text,\n",
                "            max_length=self.max_length,\n",
                "            padding='max_length',\n",
                "            truncation=True,\n",
                "            return_tensors='pt'\n",
                "        )\n",
                "        \n",
                "        input_ids = encoding['input_ids'].squeeze()\n",
                "        attention_mask = encoding['attention_mask'].squeeze()\n",
                "        labels = input_ids.clone()\n",
                "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
                "        \n",
                "        return {\n",
                "            'input_ids': input_ids,\n",
                "            'attention_mask': attention_mask,\n",
                "            'labels': labels\n",
                "        }\n",
                "\n",
                "# Create dataset and dataloader\n",
                "dataset = TeluguPoemDataset(poems, model.tokenizer, max_length=128)\n",
                "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2)\n",
                "\n",
                "print(f\"‚úÖ DataLoader ready: {len(dataloader)} batches\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch.optim import AdamW\n",
                "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Training config\n",
                "CONFIG = {\n",
                "    'epochs': 10,\n",
                "    'learning_rate': 3e-5,\n",
                "    'warmup_steps': 100,\n",
                "    'save_every': 2  # epochs\n",
                "}\n",
                "\n",
                "# Optimizer\n",
                "optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'])\n",
                "total_steps = len(dataloader) * CONFIG['epochs']\n",
                "scheduler = CosineAnnealingLR(optimizer, T_max=total_steps)\n",
                "\n",
                "# Training\n",
                "print(\"üöÄ Starting Telugu Poem Training...\")\n",
                "print(f\"   Epochs: {CONFIG['epochs']}\")\n",
                "print(f\"   Batches per epoch: {len(dataloader)}\")\n",
                "print(f\"   Total steps: {total_steps}\")\n",
                "\n",
                "model.train()\n",
                "best_loss = float('inf')\n",
                "\n",
                "for epoch in range(CONFIG['epochs']):\n",
                "    epoch_loss = 0\n",
                "    progress = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']}\")\n",
                "    \n",
                "    for batch in progress:\n",
                "        input_ids = batch['input_ids'].to(device)\n",
                "        attention_mask = batch['attention_mask'].to(device)\n",
                "        labels = batch['labels'].to(device)\n",
                "        \n",
                "        outputs = model(\n",
                "            input_ids=input_ids,\n",
                "            attention_mask=attention_mask,\n",
                "            labels=labels\n",
                "        )\n",
                "        \n",
                "        loss = outputs['loss']\n",
                "        if loss is None:\n",
                "            continue\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
                "        optimizer.step()\n",
                "        scheduler.step()\n",
                "        \n",
                "        epoch_loss += loss.item()\n",
                "        progress.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    avg_loss = epoch_loss / len(dataloader)\n",
                "    print(f\"\\nüìä Epoch {epoch+1} | Loss: {avg_loss:.4f}\")\n",
                "    \n",
                "    # Save checkpoint\n",
                "    if (epoch + 1) % CONFIG['save_every'] == 0 or avg_loss < best_loss:\n",
                "        if avg_loss < best_loss:\n",
                "            best_loss = avg_loss\n",
                "            save_path = '/content/drive/MyDrive/checkpoints/best_telugu_model.pt'\n",
                "        else:\n",
                "            save_path = f'/content/drive/MyDrive/checkpoints/telugu_epoch_{epoch+1}.pt'\n",
                "        \n",
                "        Path('/content/drive/MyDrive/checkpoints').mkdir(exist_ok=True)\n",
                "        torch.save({\n",
                "            'model_state_dict': model.state_dict(),\n",
                "            'optimizer_state_dict': optimizer.state_dict(),\n",
                "            'epoch': epoch,\n",
                "            'loss': avg_loss\n",
                "        }, save_path)\n",
                "        print(f\"üíæ Saved: {save_path}\")\n",
                "\n",
                "print(\"\\n‚úÖ Training Complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Test Generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test Telugu poem generation\n",
                "model.eval()\n",
                "\n",
                "test_prompts = [\n",
                "    \"‡∞ö‡∞Ç‡∞¶‡∞Æ‡∞æ‡∞Æ ‡∞∞‡∞æ‡∞µ‡±á\",\n",
                "    \"‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞≠‡∞æ‡∞∑\",\n",
                "    \"‡∞Ö‡∞Æ‡±ç‡∞Æ ‡∞™‡±ç‡∞∞‡±á‡∞Æ\",\n",
                "    \"‡∞®‡∞æ ‡∞¶‡±á‡∞∂‡∞Ç\"\n",
                "]\n",
                "\n",
                "print(\"üìù Telugu Poem Generation Test\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "for prompt in test_prompts:\n",
                "    print(f\"\\nüîπ Prompt: {prompt}\")\n",
                "    generated = model.generate(prompt, max_length=50, temperature=0.8)\n",
                "    print(f\"   Generated: {generated}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Save Final Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save final model to Drive\n",
                "final_path = '/content/drive/MyDrive/checkpoints/telugu_final_model.pt'\n",
                "\n",
                "torch.save({\n",
                "    'model_state_dict': model.state_dict(),\n",
                "    'config': CONFIG,\n",
                "    'final_loss': best_loss\n",
                "}, final_path)\n",
                "\n",
                "print(f\"‚úÖ Final model saved to: {final_path}\")\n",
                "print(f\"\\nüìã To use this model locally:\")\n",
                "print(f\"   1. Download from Google Drive\")\n",
                "print(f\"   2. Place in project checkpoints/ folder\")\n",
                "print(f\"   3. Load with: torch.load('checkpoints/telugu_final_model.pt')\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}